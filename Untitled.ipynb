{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/train.csv')\n",
    "df_test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[df.columns[1:-1]].to_numpy()\n",
    "y_train = train[df.columns[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[df.columns[1:-1]].to_numpy()\n",
    "y_test = test[df.columns[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 10), (2500, 10))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Введем функцию подсчета точности R2\n",
    "def r2(y_real, y_pred):\n",
    "    r2 = 1 - np.sum(np.square(y_real - y_pred))/np.sum(np.square(y_real - y_real.mean()))\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree():\n",
    "    \n",
    "    '''\n",
    "    Класс RegressionTree решает задачу регрессии. Основан на рекурсивных\n",
    "    вызовах, когда прописываются условия выхода из рекурсии. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_depth=3, n_epoch=10, min_size=8):\n",
    "        \n",
    "        '''\n",
    "        Объявляем переменные класса.\n",
    "        '''\n",
    "        \n",
    "        self.max_depth = max_depth # максимальная глубина\n",
    "        self.min_size = min_size # минимальный размер поддерева\n",
    "        self.value = 0 # значение в поддереве (среднее по всем листьям)\n",
    "        self.feature_idx = -1 # номер лучшего признака\n",
    "        self.feature_threshold = 0 # значение лучшего признака\n",
    "        self.left = None # левый потомок\n",
    "        self.right = None # правый потомок\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        '''\n",
    "        Процедура обучения дерева. На выходе получим обученную модель.\n",
    "        '''\n",
    "        \n",
    "        # инициализируем начальные значения\n",
    "        self.value = y.mean()\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # ошибки в левом и правом поддереве\n",
    "        prev_error_left = base_error\n",
    "        prev_error_right = 0\n",
    "        \n",
    "        # если дошли до глубины 0 - выходим\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        # значения в левом и правом поддереве\n",
    "        left_value = 0\n",
    "        right_value = 0\n",
    "        \n",
    "        # начинаем цикл по признакам\n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            # сортируем признаки\n",
    "            idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # количество сэмплов в левом и правом поддереве\n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            # начинаем проходиться по значениям признака\n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "                \n",
    "                idx = idxs[thres]\n",
    "                x = X[idx, feat]\n",
    "                \n",
    "                # пропускаем одинаковые признаки\n",
    "                if thres < N - 1 and x == X[idxs[thres + 1], feat]:\n",
    "\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # данные, которые получаются у нас в результате такого сплита\n",
    "                target_right = y[idxs][:thres]\n",
    "                target_left = y[idxs][thres:]\n",
    "                mean_right = y[idxs][:thres].mean(), \n",
    "                mean_left = y[idxs][thres:].mean()\n",
    "                \n",
    "                # на этом шаге уже нужно считать ошибку - \n",
    "                # генерируем предикты (среднее в потомках)\n",
    "                left_shape = target_left.shape[0]\n",
    "                right_shape = target_right.shape[0]\n",
    "                mean_left_array = [mean_left for _ in range(left_shape)]\n",
    "                mean_right_array = [mean_right for _ in range(right_shape)]\n",
    "                \n",
    "                # считаем ошибку слева и справа\n",
    "                prev_error_left = N1/N * mse(target_left, mean_left_array) \n",
    "                prev_error_right = N2/N * mse(target_right, mean_right_array)\n",
    "                \n",
    "                # если выполняются условия сплита, то обновляем\n",
    "                if (prev_error_left + prev_error_right < error):\n",
    "                        if (min(N1,N2) > self.min_size):\n",
    "                            self.feature_idx = feat\n",
    "                            self.feature_threshold = x\n",
    "                            left_value = mean_left\n",
    "                            right_value = mean_right\n",
    "\n",
    "                            flag = 1\n",
    "                            error = prev_error_left + prev_error_right\n",
    "                                     \n",
    "                thres += 1\n",
    "        \n",
    "        # если не нашли лучший сплит, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        # дошли сюда - есть хорошее разбиение, нужно обучать дальше\n",
    "        # инициализируем потомков - те же деревья решений\n",
    "        self.left = RegressionTree(self.max_depth - 1)\n",
    "        self.left.value = left_value\n",
    "        self.right = RegressionTree(self.max_depth - 1)\n",
    "        self.right.value = right_value\n",
    "        \n",
    "        # индексы потомков\n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "        \n",
    "        # обучаем\n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        \n",
    "        '''\n",
    "        Функция для генерирования предсказания - смотрим узлы, идем \n",
    "        в соответствующих  потомков и смотрим в конце self.value - это\n",
    "        и будет ответом.\n",
    "        '''\n",
    "        \n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        '''\n",
    "        Предикт для матрицы - просто для каждой строчки вызываем __predict().\n",
    "        '''\n",
    "        \n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 315 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A = RegressionTree(2) # это наш алгоритм\n",
    "A.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = DecisionTreeRegressor(max_depth=2)\n",
    " # из Sklearn\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTreeFastMse():\n",
    "    \n",
    "    '''\n",
    "    Класс RegressionTree с быстрым пересчетом ошибки. Сложность пересчета ошибки\n",
    "    на каждой итерации составляет O(1).\n",
    "    '''\n",
    "    \n",
    "    # объявляем характеристики класса\n",
    "    def __init__(self, max_depth=3, min_size=10):\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.value = 0\n",
    "        self.feature_idx = -1\n",
    "        self.feature_threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    # процедура обучения - сюда передается обучающая выборка\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # начальное значение - среднее значение y\n",
    "        self.value = y.mean()\n",
    "        # начальная ошибка - mse между значением в листе (пока нет\n",
    "        # разбиения, это среднее по всем объектам) и объектами\n",
    "        base_error = ((y - self.value) ** 2).sum()\n",
    "        error = base_error\n",
    "        flag = 0\n",
    "        \n",
    "        # пришли в максимальную глубину\n",
    "        if self.max_depth <= 1:\n",
    "            return\n",
    "    \n",
    "        dim_shape = X.shape[1]\n",
    "        \n",
    "        left_value, right_value = 0, 0\n",
    "        \n",
    "        for feat in range(dim_shape):\n",
    "            \n",
    "            prev_error1, prev_error2 = base_error, 0 \n",
    "            idxs = np.argsort(X[:, feat])\n",
    "            \n",
    "            # переменные для быстрого переброса суммы\n",
    "            mean1, mean2 = y.mean(), 0\n",
    "            sm1, sm2 = y.sum(), 0\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            N1, N2 = N, 0\n",
    "            thres = 1\n",
    "            \n",
    "            while thres < N - 1:\n",
    "                N1 -= 1\n",
    "                N2 += 1\n",
    "\n",
    "                idx = idxs[thres]\n",
    "                x = X[idx, feat]\n",
    "                \n",
    "                # вычисляем дельты - по ним в основном будет делаться переброс\n",
    "                delta1 = (sm1 - y[idx]) * 1.0 / N1 - mean1\n",
    "                delta2 = (sm2 + y[idx]) * 1.0 / N2 - mean2\n",
    "                \n",
    "                # увеличиваем суммы\n",
    "                sm1 -= y[idx]\n",
    "                sm2 += y[idx]\n",
    "                \n",
    "                # пересчитываем ошибки за O(1)\n",
    "                prev_error1 += (delta1**2) * N1 \n",
    "                prev_error1 -= (y[idx] - mean1)**2 \n",
    "                prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1)\n",
    "                mean1 = sm1/N1\n",
    "                \n",
    "                prev_error2 += (delta2**2) * N2 \n",
    "                prev_error2 += (y[idx] - mean2)**2 \n",
    "                prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2)\n",
    "                mean2 = sm2/N2\n",
    "                \n",
    "                # пропускаем близкие друг к другу значения\n",
    "                if thres < N - 1 and np.abs(x - X[idxs[thres + 1], feat]) < 1e-5:\n",
    "                    thres += 1\n",
    "                    continue\n",
    "                \n",
    "                # 2 условия, чтобы осуществить сплит - уменьшение ошибки \n",
    "                # и минимальное кол-о эл-в в каждом листе\n",
    "                if (prev_error1 + prev_error2 < error):\n",
    "                    if (min(N1,N2) > self.min_size):\n",
    "                    \n",
    "                        # переопределяем самый лучший признак и границу по нему\n",
    "                        self.feature_idx, self.feature_threshold = feat, x\n",
    "                        # переопределяем значения в листах\n",
    "                        left_value, right_value = mean1, mean2\n",
    "\n",
    "                        # флаг - значит сделали хороший сплит\n",
    "                        flag = 1\n",
    "                        error = prev_error1 + prev_error2\n",
    "                                     \n",
    "                thres += 1\n",
    " \n",
    "        # ничего не разделили, выходим\n",
    "        if self.feature_idx == -1:\n",
    "            return\n",
    "        \n",
    "        self.left = RegressionTreeFastMse(self.max_depth - 1)\n",
    "        # print (\"Левое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.left.value = left_value\n",
    "        self.right = RegressionTreeFastMse(self.max_depth - 1)\n",
    "        # print (\"Правое поддерево с глубиной %d\"%(self.max_depth - 1))\n",
    "        self.right.value = right_value\n",
    "        \n",
    "        idxs_l = (X[:, self.feature_idx] > self.feature_threshold)\n",
    "        idxs_r = (X[:, self.feature_idx] <= self.feature_threshold)\n",
    "    \n",
    "        self.left.fit(X[idxs_l, :], y[idxs_l])\n",
    "        self.right.fit(X[idxs_r, :], y[idxs_r])\n",
    "        \n",
    "    def __predict(self, x):\n",
    "        if self.feature_idx == -1:\n",
    "            return self.value\n",
    "        \n",
    "        if x[self.feature_idx] > self.feature_threshold:\n",
    "            return self.left.__predict(x)\n",
    "        else:\n",
    "            return self.right.__predict(x)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__predict(X[i])\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A = RegressionTreeFastMse(7, min_size=5)\n",
    "A.fit(X_train,y_train)\n",
    "train_answers = A.predict(X_train)\n",
    "test_answers = A.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7688897861470159"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_test, test_answers)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7681489126434825 RegressionTreeFastMse(8, min_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting():\n",
    "    \n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, \n",
    "                 random_state=17, n_samples = 15, min_size = 5, base_tree='Bagging'):\n",
    "            \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.initialization = lambda y: np.mean(y) * np.ones([y.shape[0]])\n",
    "        self.min_size = min_size\n",
    "        self.loss_by_iter = []\n",
    "        self.trees_ = []\n",
    "        self.loss_by_iter_test = []\n",
    "        self.n_samples = n_samples\n",
    "        self.base_tree = base_tree\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        b = self.initialization(y)\n",
    "        \n",
    "        prediction = b.copy()\n",
    "        \n",
    "        for t in tqdm_notebook(range(self.n_estimators)):               \n",
    "            \n",
    "            if t == 0:\n",
    "                resid = y\n",
    "            else:\n",
    "                # сразу пишем антиградиент\n",
    "                resid = (y - prediction)\n",
    "            \n",
    "            # выбираем базовый алгоритм\n",
    "            if self.base_tree == 'Bagging':\n",
    "                tree = Bagging(max_depth=self.max_depth,\n",
    "                                       min_size = self.min_size)                \n",
    "            if self.base_tree == 'Tree':\n",
    "                tree = RegressionTreeFastMse(max_depth=self.max_depth,\n",
    "                                          min_size = self.min_size)\n",
    "                \n",
    "            # обучаемся на векторе антиградиента\n",
    "            tree.fit(X, resid)\n",
    "            # делаем предикт и добавляем алгоритм к ансамблю\n",
    "            b = tree.predict(X).reshape([X.shape[0]])\n",
    "            self.trees_.append(tree)\n",
    "            prediction += self.learning_rate * b\n",
    "            # добавляем только если не первая итерация\n",
    "            if t > 0:\n",
    "                self.loss_by_iter.append(mse(y,prediction))\n",
    "                   \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # сначала прогноз – это просто вектор из средних значений ответов на обучении\n",
    "        pred = np.ones([X.shape[0]]) * np.mean(self.y)\n",
    "        # добавляем прогнозы деревьев\n",
    "        for t in range(self.n_estimators):\n",
    "            pred += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0]])\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging():\n",
    "    \n",
    "    '''\n",
    "    Класс Bagging - предназначен для генерирования бустрапированного\n",
    "    выбора моделей.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_depth = 3, min_size=10, n_samples = 10):\n",
    "            \n",
    "        #super(CART, self).__init__()\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.n_samples = n_samples\n",
    "        self.subsample_size = None\n",
    "        self.list_of_Carts = [RegressionTreeFastMse(max_depth=self.max_depth, \n",
    "                                min_size=self.min_size) for _ in range(self.n_samples)]\n",
    "\n",
    "    def get_bootstrap_samples(self, data_train, y_train):\n",
    "        \n",
    "        # генерируем индексы выборок с возращением\n",
    "        indices = np.random.randint(0, len(data_train), (self.n_samples, self.subsample_size))\n",
    "        samples_train = data_train[indices]\n",
    "        samples_y = y_train[indices]\n",
    "        return samples_train, samples_y\n",
    "    \n",
    "    def fit(self, data_train, y_train):\n",
    "        \n",
    "        # обучаем каждую модель \n",
    "        self.subsample_size = int(data_train.shape[0])\n",
    "        samples_train, samples_y = self.get_bootstrap_samples(data_train, y_train)\n",
    "        for i in range(self.n_samples):\n",
    "            self.list_of_Carts[i].fit(samples_train[i], samples_y[i].reshape(-1))\n",
    "        return self\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        # для каждого объекта берём его средний предикт\n",
    "        num_samples = test_data.shape[0]\n",
    "        pred = []\n",
    "        for i in range(self.n_samples):\n",
    "            pred.append(self.list_of_Carts[i].predict(test_data))\n",
    "        pred = np.array(pred).T\n",
    "\n",
    "        return np.array([np.mean(pred[i]) for i in range(num_samples)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c67b7dece642518bbd2c20272ffb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GDB = GradientBoosting(n_estimators=1500, base_tree='Tree', max_depth=6, learning_rate=0.05)\n",
    "GDB.fit(X_train,y_train)\n",
    "test_answers_GB = GDB.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bde398656834b9684483080b9130682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GDB_2 = GradientBoosting(n_estimators=500, base_tree='Bagging', max_depth=7)\n",
    "GDB_2.fit(X_train,y_train)\n",
    "test_answers_GB_2 = GDB_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers_GB = GDB.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570088068013311"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_train, train_answers_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7776435441960861"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_test, test_answers_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523078031888472"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_test, test_answers_GB_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7376629239784604, 0.7751116388030227 n_estimators=100, base_tree='Tree', max_depth=7       0.7761619059581079 (n_estimators=100, base_tree='Tree', max_depth=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7794270033401676 (n_estimators=100, base_tree='Tree', max_depth=6)   0.7778799618813317 n_estimators=500, base_tree='Tree', max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26a06b406a0>]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.title('Loss by iterations')\n",
    "plt.plot(GDB.loss_by_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на всем датасете и сделаем предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:-1]].to_numpy()\n",
    "y = df[df.columns[-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5f529007e84777b9a5c85903655b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GradientBoosting at 0x26a06b80c18>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDB_pred = GradientBoosting(n_estimators=1500, base_tree='Tree', max_depth=7, learning_rate=0.05)\n",
    "GDB_pred.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test[df_test.columns[1:]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = GDB_pred.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['mean_exam_points'] = test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_write = df_test[['Id', 'mean_exam_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_write.to_csv('nnm_preds_gdb_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.85526738, 57.20370968, 52.84016981, ..., 54.5883836 ,\n",
       "       59.02716867, 67.83128502])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
